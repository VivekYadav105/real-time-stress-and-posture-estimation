{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5j7qXqYn_cH",
        "outputId": "91557352-1b41-4e95-8250-170838bc65f2"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow-gpu\n",
        "%pip install tensorflow_hub #TensorFlow Hub is a repository of trained machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjJUNBI3uV_8"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tjai_2Yom8ok",
        "outputId": "1fc579bf-4c5e-4d59-8e0a-71179f6e0328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15.0\n"
          ]
        }
      ],
      "source": [
        "print(hub.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Hb5T2Wumuk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.precision\", 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omKPwTcnwYwb",
        "outputId": "48d54489-8ca1-4020-c625-68a8e5cacbf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiMaaYVN2Qdf"
      },
      "source": [
        "Set your training folder which contains images\n",
        "\n",
        "[Drive Link](https://drive.google.com/drive/folders/1kdwUgvyqoN5JZD6q9T1YH0OKChH64Vtd?usp=share_link)\n",
        "\n",
        "P.S: You can use shoe folder from this [Git repo](https://github.com/rfatcakr/Tensorflow_object_training/tree/master/sample_inputs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7egL_rVjs9FK"
      },
      "outputs": [],
      "source": [
        "data_root = '/content/drive/MyDrive/10%'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ5ou5H73CMM",
        "outputId": "d8576b71-d9c9-4550-a42e-71dba218a4ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/10%\n",
            "Found 474 images belonging to 2 classes.\n",
            "Found 1898 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "TRAINING_DATA_DIR = str(data_root)\n",
        "print(TRAINING_DATA_DIR);\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"validation\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    color_mode=\"rgb\"\n",
        ")\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    color_mode=\"rgb\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ug8XgJn3g7-",
        "outputId": "b5023210-5d13-4c65-cfde-31b86fc966ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image batch shape:  (32, 224, 224, 3)\n",
            "Label batch shape:  (32, 2)\n",
            "['Not_Stress' 'Stress']\n"
          ]
        }
      ],
      "source": [
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG1HaZS7OWuO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEI0CA-OQCsl",
        "outputId": "b87614e7-c5c8-41c4-e5b9-8ee88941de37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1001)              6633209   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6633209 (25.30 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 6633209 (25.30 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#regnety\n",
        "model_regnety = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v1/classification/5\")\n",
        "])\n",
        "model_regnety.build([None, 224, 224, 3])  # Batch input shape.\n",
        "model_regnety.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSKTdhGbQhuS"
      },
      "outputs": [],
      "source": [
        "model_regnety.add(tf.keras.layers.Dense(2, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh7o0uxEQ2Js"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yA7FmZgQon_"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "\n",
        "]\n",
        "\n",
        "model_regnety.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5eyN4OmQ04m",
        "outputId": "925ecb8d-e7ac-4305-b221-d61f19481410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 552s 9s/step - loss: 0.5714 - tp: 1370.0000 - fp: 528.0000 - tn: 1370.0000 - fn: 528.0000 - accuracy: 0.7218 - precision: 0.7218 - recall: 0.7218 - auc: 0.7941 - prc: 0.7877 - val_loss: 0.5150 - val_tp: 367.0000 - val_fp: 107.0000 - val_tn: 367.0000 - val_fn: 107.0000 - val_accuracy: 0.7743 - val_precision: 0.7743 - val_recall: 0.7743 - val_auc: 0.8481 - val_prc: 0.8424\n"
          ]
        }
      ],
      "source": [
        "\n",
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "\n",
        "hist = model_regnety.fit(\n",
        "    train_generator,\n",
        "    epochs=1,\n",
        "    verbose=1,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=val_steps_per_epoch).history\n",
        "\n",
        "# steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "# val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "\n",
        "# hist = model_regnety.fit(\n",
        "#     train_generator,\n",
        "#     epochs=10,\n",
        "#     verbose=1,\n",
        "#     steps_per_epoch=steps_per_epoch,\n",
        "#     validation_data=valid_generator,\n",
        "#     validation_steps=val_steps_per_epoch).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUeQgOiDoDGU"
      },
      "outputs": [],
      "source": [
        "# saved_model_path = 'my_model_3nov.h5' # or you can simply use 'my_mode.h5'\n",
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "model_regnety.save('my_model_4nov.keras') #save your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEYRt8MhosrW"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('my_model_4nov.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-dysVthqTkO"
      },
      "outputs": [],
      "source": [
        "# model_regnety.predict('/content/drive/MyDrive/10%/stress/33422.jpg')\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('/content/drive/MyDrive/10%/stress/33422.jpg')\n",
        "\n",
        "# Preprocess the image (resize, normalize, etc.)\n",
        "# Ensure that it matches the expected input shape of your model\n",
        "image = cv2.resize(image, (224, 224))  # Replace 'height' and 'width' with the appropriate values\n",
        "image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "# Reshape the image to match the expected input shape (add batch dimension)\n",
        "input_data = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model_regnety.predict(input_data)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFC-LgE6rgys"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a list of class labels\n",
        "class_labels = [\"Class 0\", \"Class 1\"]\n",
        "\n",
        "# Assuming 'predictions' is a numpy array with class probabilities\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    plt.imshow(input_data[i])  # Display the input image\n",
        "    plt.title(f'Predicted Class: {class_labels[predicted_classes[i]]}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7bmrHzorwJ7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'predictions' is a numpy array with class probabilities\n",
        "# and 'class_labels' is a list of class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the corresponding class labels\n",
        "predicted_labels = [class_labels[i] for i in predicted_classes]\n",
        "\n",
        "# Now, 'predicted_labels' contains the class labels for each prediction\n",
        "print(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YElq6bohpUQG"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj7hhc4tpfB3"
      },
      "outputs": [],
      "source": [
        "# to reload your model\n",
        "# shoe_model = keras.models.load_model(saved_model_path)\n",
        "shoe_model = tf.keras.models.load_model(\n",
        "       (\"/content/MY_MODE\"),\n",
        "       custom_objects={'KerasLayer':hub.KerasLayer}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyWIPMhIOtW3"
      },
      "outputs": [],
      "source": [
        "# Get images and labels batch from validation dataset generator\n",
        "\n",
        "val_image_batch, val_label_batch = next(iter(valid_generator))\n",
        "true_label_ids = np.argmax(val_label_batch, axis=-1)\n",
        "\n",
        "print(\"Validation batch shape:\", val_image_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4Cu8rlgO4Vf"
      },
      "outputs": [],
      "source": [
        "tf_model_predictions = shoe_model.predict(val_image_batch)\n",
        "print(\"Prediction results shape:\", tf_model_predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44n9E2ldO_VM"
      },
      "outputs": [],
      "source": [
        "tf_pred_dataframe = pd.DataFrame(tf_model_predictions)\n",
        "tf_pred_dataframe.columns = dataset_labels\n",
        "\n",
        "print(\"Prediction results for the first elements\")\n",
        "tf_pred_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp7Gh7pWPFqN"
      },
      "outputs": [],
      "source": [
        "predicted_ids = np.argmax(tf_model_predictions, axis=-1)\n",
        "predicted_labels = dataset_labels[predicted_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plEqTUNbPKtE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(val_image_batch[n])\n",
        "  color = \"green\" if predicted_ids[n] == true_label_ids[n] else \"red\"\n",
        "  plt.title(predicted_labels[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"./results/only-stress-results.jpg\" style=\"width:500px;height:500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHEI8ZX2OaPk"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.make_archive('MY_MODE.zip', 'zip', 'MY_MODE')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
